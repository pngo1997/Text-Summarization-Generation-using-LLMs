{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOf9HQcHl4Fknu5tAmxzz9E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1d36daa7efd849e3b8b01469c5fa3be7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_878bd5504c8d4016b92e7b15b617a3db","IPY_MODEL_8019f53d7354429c89dac55cc7840da0","IPY_MODEL_35b1301105a440ee96af14ef66b53dbc"],"layout":"IPY_MODEL_775fd2a675e44d399629c13cfab4343a"}},"878bd5504c8d4016b92e7b15b617a3db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e3f71a6ebf94309a8aaff5620e80626","placeholder":"â€‹","style":"IPY_MODEL_00a64689a9ef496bab7c28ab9ccc2cbe","value":"Loadingâ€‡checkpointâ€‡shards:â€‡100%"}},"8019f53d7354429c89dac55cc7840da0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c36030d9e061441389fdcc2442460766","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1fb0859c1e574205ba82b6714be25ca5","value":3}},"35b1301105a440ee96af14ef66b53dbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f923374048424e50b645f06ef65d9327","placeholder":"â€‹","style":"IPY_MODEL_ec4fee331d3544bbaa5413df682c8791","value":"â€‡3/3â€‡[00:05&lt;00:00,â€‡â€‡1.71s/it]"}},"775fd2a675e44d399629c13cfab4343a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e3f71a6ebf94309a8aaff5620e80626":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00a64689a9ef496bab7c28ab9ccc2cbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c36030d9e061441389fdcc2442460766":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb0859c1e574205ba82b6714be25ca5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f923374048424e50b645f06ef65d9327":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec4fee331d3544bbaa5413df682c8791":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#### Student Name: Mai Ngo\n","#### Course Name and Number: CSC 583 Natural Language Processing\n","#### Assignment 5 - Text Summarization & Generation using LLMs\n","#### Date: 11/7/2024"],"metadata":{"id":"y8blrtechcJP"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"bqbLcL1Og_ov","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731001168038,"user_tz":360,"elapsed":13764,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}},"outputId":"a6e4b70f-507f-475e-891e-c7f4648718c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/CSC583\n"]}],"source":["#Mount my Google Drive.\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","import os\n","directory = '/content/drive/My Drive/CSC583'\n","os.chdir(directory)\n","#Ensure the files are there (in the folder).\n","!pwd"]},{"cell_type":"code","source":["#Some important import's.\n","import pandas as pd\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","from huggingface_hub import login"],"metadata":{"id":"CEE3AZHiioJi","executionInfo":{"status":"ok","timestamp":1731007098397,"user_tz":360,"elapsed":88,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}}},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":["# **Part III: Summarization by Prompting using LLM Decoder Models.**"],"metadata":{"id":"KHm_jw0ahoXB"}},{"cell_type":"markdown","source":["## **Access SOTA LLMs - Load Open-source Decoder(only) Model -- Using Mistral Model.**"],"metadata":{"id":"-Ge8k0ICfEUJ"}},{"cell_type":"code","source":["login(\"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\")\n","torch.manual_seed(1997)\n","tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n","\n","#Set pad_token_id to eos_token_id to ensure padding is treated as end of sequence.\n","tokenizer.pad_token_id = tokenizer.eos_token_id\n","#Set text generation pipeline.\n","pipe = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.2\", tokenizer = tokenizer, torch_dtype=torch.bfloat16, device_map=\"auto\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["1d36daa7efd849e3b8b01469c5fa3be7","878bd5504c8d4016b92e7b15b617a3db","8019f53d7354429c89dac55cc7840da0","35b1301105a440ee96af14ef66b53dbc","775fd2a675e44d399629c13cfab4343a","6e3f71a6ebf94309a8aaff5620e80626","00a64689a9ef496bab7c28ab9ccc2cbe","c36030d9e061441389fdcc2442460766","1fb0859c1e574205ba82b6714be25ca5","f923374048424e50b645f06ef65d9327","ec4fee331d3544bbaa5413df682c8791"]},"id":"RuBnlij3ti-I","executionInfo":{"status":"ok","timestamp":1731003485186,"user_tz":360,"elapsed":5750,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}},"outputId":"747f00d3-bf58-4bee-8533-f75055d3d63b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d36daa7efd849e3b8b01469c5fa3be7"}},"metadata":{}}]},{"cell_type":"markdown","source":["## **Create Prompts.**"],"metadata":{"id":"3Q1PqZbxDf9v"}},{"cell_type":"markdown","source":["### **Prompt 1: Reasoning + Few-shot Prompting.**"],"metadata":{"id":"e_buG_nC0Hq_"}},{"cell_type":"code","source":["prompt = \"\"\"\n","Q: Candidate A needs 270 votes to win and has 250 votes.\n","   The remaining states are State X (5 votes) and State Y (10 votes).\n","   Can Candidate A win the election?\n","A: No\n","\n","Q: Kamala needs at least 270 electoral votes to win the presidency.\n","   She currently has 226 votes. Only Wisconsin (10 votes), Michigan (15 votes),\n","   and Pennsylvania (19 votes) are left.\n","   Can Kamala win the election? Answer \"Yes\" or \"No.\n","   If \"Yes\" list the states she must win.\"\n","A:\n","\"\"\"\n","sequences = pipe(\n","    prompt,\n","    max_new_tokens=26,\n","    do_sample=False,\n","    temperature = 0,\n","    return_full_text=False)\n","\n","for seq in sequences:\n","    print(f\"Result: {seq['generated_text']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"feE5jvqF0HLi","executionInfo":{"status":"ok","timestamp":1731006704600,"user_tz":360,"elapsed":1259,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}},"outputId":"4f070392-5571-408b-e807-93eaed0fcd48"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Result: Yes, Kamala Harris can win the election if she wins all the remaining electoral votes in Michigan, Pennsylvania, and Wisconsin.\n"]}]},{"cell_type":"markdown","source":["### **Prompt 2: Question answering.**"],"metadata":{"id":"oyO2zwc29rJ8"}},{"cell_type":"code","source":["prompt2 = \"\"\"Here is a list of ingredients for chicken soup:\n","\n","1 tablespoon avocado oil or olive oil\n","6 cloves of garlic, minced\n","1 yellow onion, diced\n","2 large carrots, thinly sliced\n","2 celery stalks, roughly chopped\n","1 tablespoon fresh grated ginger\n","1 tablespoon fresh grated turmeric (or 1 teaspoon ground turmeric)*\n","6 cups low sodium chicken broth\n","1 pound boneless skinless chicken breast or thighs\n","1 teaspoon freshly chopped rosemary\n","1 teaspoon freshly chopped thyme, stems removed\n","Â½ teaspoon salt\n","Freshly ground black pepper\n","1 cup pearl couscous\n","â…” cup frozen peas (optional, but recommended)\n","\n","Question: Give me a list of vegetable and herbs ingridients I need to buy based on the recipe.\"\"\"\n","\n","sequences = pipe(\n","    prompt2,\n","    max_new_tokens=200,\n","    do_sample=True,\n","    top_k=10,\n","    return_full_text = False,\n",")\n","\n","for seq in sequences:\n","    print(f\"{seq['generated_text']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFNAXJV_vXJ9","executionInfo":{"status":"ok","timestamp":1731006674173,"user_tz":360,"elapsed":8574,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}},"outputId":"f03f1d53-7e42-4f92-e548-671386b642c4"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","Answer: Based on the chicken soup recipe, here is a list of vegetable and herb ingredients you need to buy:\n","\n","- 2 large carrots\n","- 2 celery stalks\n","- 1 yellow onion\n","- 1 cup frozen peas (optional)\n","\n","For herbs:\n","- Fresh ginger \n","- Fresh turmeric (or 1 tsp ground turmeric)\n","- Fresh rosemary\n","- Fresh thyme (stems removed)\n","\n","Additionally, you will need the following pantry staples:\n","- Avocado oil or olive oil\n","- Minced garlic (or fresh garlic)\n","- Low sodium chicken broth\n","- Salt\n","- Freshly ground black pepper\n","- Pearl couscous\n","\n","Hope this helps! Let me know if you need anything else. ðŸ˜Š\n"]}]},{"cell_type":"markdown","source":["## **Use the two essays I chose in Part II, send each one to the LLM with a prompt, for each prompt.**"],"metadata":{"id":"ZSMiBZsHDsRp"}},{"cell_type":"markdown","source":["### **Load the Data.**"],"metadata":{"id":"GutzFCaRwo7P"}},{"cell_type":"code","source":["data = pd.read_csv('essays.csv')\n","print(f'Essay data shape: {data.shape}')\n","data = data.drop(['authors', 'source_url', 'thumbnail_url'], axis=1)\n","trainData = data.iloc[:1600]\n","valData = data.iloc[1600:1800]\n","testData = data.iloc[1800:]\n","testData.reset_index(drop=True, inplace=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxlAwvOBeYTj","executionInfo":{"status":"ok","timestamp":1731007366112,"user_tz":360,"elapsed":725,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}},"outputId":"c4bc3d3a-88d4-4f3d-dfb8-f0678299385b"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Essay data shape: (2235, 6)\n"]}]},{"cell_type":"markdown","source":["### **Retrieve Essays.**"],"metadata":{"id":"MIjEklOHEtwx"}},{"cell_type":"code","source":["firstEssay = testData.loc[0, 'essay']\n","prompt3 = \"Give a summary (in bulettin points) of this essay:\\n \" + firstEssay\n","sixthEssay = testData.loc[7, 'essay']\n","prompt4 = \"Give a summary (in bulettin points) of this essay:\\n \" + sixthEssay"],"metadata":{"id":"VisXIpU_xkB7","executionInfo":{"status":"ok","timestamp":1731009085573,"user_tz":360,"elapsed":98,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["#First Essay.\n","sequences = pipe(\n","  prompt3,\n","  max_new_tokens=300,\n","  do_sample=True,\n","  top_k=10,\n","  return_full_text = False)\n","print('Summary of first essay in test data as bulettin point:')\n","for seq in sequences:\n","  print(f\"{seq['generated_text']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAMIeoAEFfzf","executionInfo":{"status":"ok","timestamp":1731009375181,"user_tz":360,"elapsed":13996,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}},"outputId":"dece7660-f4c2-423a-a16c-4f455fb73140"},"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary of first essay in test data as bulettin point:\n","\n","- The Ebola virus has killed hundreds in Africa in 2014 and raised concerns about it spreading to the US\n","- Ebola spreads through intimate contact with infected body fluids and is not likely to cause a pandemic\n","- Pandemic paranoia has been fueled by books like \"The Coming Plague\" and \"Hot Zone\"\n","- Historical pandemics, such as the Antonine Plague, the Justinian Plague, and the Black Death, have caused millions of deaths\n","- Frank Macfarlane Burnet argued that the deadliest diseases are those newly introduced into the human species\n","- Many health experts believe that human intrusion into the natural world increases the risk of pandemics\n","- However, the most dangerous infectious diseases are often those that have adapted to humanity over time\n","- Natural selection pushes circulating strains towards more effective transmission and adaptation to human hosts\n","- The Great Plague of Athens is an example of how a disease can evolve in a 'disease factory' or place where the sick are trapped with the well, causing infection to spread rapidly\n","- Fighting existing pathogens is more urgent than hunting for possible new ones to prevent real suffering in the world\n","- Prevention of disease factories, such as trench-like warfare conditions, crowded hospitals, and enormous refugee camps, is our best protection against pandemics.\n"]}]},{"cell_type":"code","source":["#Sixth Essay.\n","sequences = pipe(\n","  prompt4,\n","  max_new_tokens=300,\n","  do_sample=True,\n","  top_k=10,\n","  return_full_text = False)\n","print('Summary of sixth essay in test data as bulettin point:')\n","for seq in sequences:\n","  print(f\"{seq['generated_text']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-56tlrKHXIa","executionInfo":{"status":"ok","timestamp":1731009560595,"user_tz":360,"elapsed":14084,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}},"outputId":"77e9db13-2bd0-4035-cc7a-0bdee07298a1"},"execution_count":130,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary of sixth essay in test data as bulettin point:\n","\n","- 12-Step Programs, such as Drunks-R-Us, are based on spiritual principles for recovering from addiction through peer support.\n","- AA is one of the most well-known 12-step programs, founded in 1939 by Bill Wilson, a Wall Street stockbroker from Vermont.\n","- The 12 steps include admitting powerlessness over addiction, turning oneself over to a higher power, taking a fearless moral inventory, and making amends to those who have been harmed.\n","- AA's teachings have been the basis for treatment at many rehab facilities and for the adoption of the 12-step approach for other addictions, such as Narcotics Anonymous.\n","- Although addiction has been better understood through neuroscience and new cognitive and drug therapies, AA remains the overwhelming treatment of choice.\n","- Critics argue that the science in the Big Book, AA's main text, is outdated and that the one-size-fits-all therapy doesn't address every facet of addiction, including the role of trauma and mental illness.\n","- Research shows that addiction is rooted in brain circuitry and is often a consequence of childhood trauma or other neuropsychiatric disease.\n","- Newer therapies are emerging, but they are not yet proven to be effective and are not accessible to everyone, particularly those in the criminal justice\n"]}]},{"cell_type":"markdown","source":["## **Write to a PDF File.**"],"metadata":{"id":"MoKptt-5k16N"}},{"cell_type":"code","source":["#!apt-get -qq install -y pandoc > /dev/null 2>&1\n","#!apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic > /dev/null 2>&1\n","#!apt-get update > /dev/null 2>&1\n","#!apt-get install -y texlive-xetex texlive-fonts-recommended texlive-plain-generic > /dev/null 2>&1\n","!jupyter nbconvert --to pdf \"/content/drive/MyDrive/CSC583/CSC583 - Assignment 5 - Part 3.ipynb\" > /dev/null 2>&1"],"metadata":{"id":"8yi-aNJJhq9X","executionInfo":{"status":"ok","timestamp":1731009668971,"user_tz":360,"elapsed":8135,"user":{"displayName":"Mai Ngo","userId":"00292170341618798690"}}},"execution_count":131,"outputs":[]}]}